#include <glog/logging.h>
#include <stdio.h>
#include <stdlib.h>
#include <deque>
#include <map>
#include <string>
#include <iostream>
#include <vector>

#include "server/messages.h"
#include "server/master.h"


using namespace std;

const int pthread_num = 24;

struct Worker_state{
    bool is_alive;
    bool claim_closed;
    int cpu_reqnum;
    int mem_reqnum;
    int cache_reqnum;
    int idle_period;
};
static struct Master_state {

  // The mstate struct collects all the master node state into one
  // place.  You do not need to preserve any of the fields below, they
  // exist only to implement the basic functionality of the starter
  // code.

  bool server_ready;
  int max_num_workers;
  int cur_num_workers;
  int num_pending_client_requests;
  int next_tag;
   Worker_state ws[4];
  deque<Request_msg> waitlist;
  map<int, Client_handle> clientMap;
  map<int, Request_msg> requestMap;

  // structure for countprime
  map<int, int> respNumMap;
  map<int, vector<int> > countListMap;

  map<string, Response_msg> cache;

  Worker_handle my_worker[4]; //at most four worker handles
  int wtag[4]; //the tag (the name of a worker handle)
  Client_handle waiting_client;
  int idle_cycle;

   int cpuit;
   int cacheit;
   int randit;
} mstate;



void master_node_init(int max_workers, int& tick_period) {

  // set up tick handler to fire every 5 seconds. (feel free to
  // configure as you please)
  tick_period = 2;

  mstate.next_tag = 0;
  mstate.max_num_workers = max_workers;
  mstate.num_pending_client_requests = 0;

  // don't mark the server as ready until the server is ready to go.
  // This is actually when the first worker is up and running, not
  // when 'master_node_init' returnes
  mstate.server_ready = false;

  // fire off a request for a new worker
  mstate.cur_num_workers = 0;
  for(int i = 0; i < 4;i++){
    mstate.ws[i].is_alive = false;
    mstate.ws[i].claim_closed = false;
    //mstate.my_worker[i].
  }
  int tag = random();
  Request_msg req(tag);
  req.set_arg("name", "my worker 0");
  request_new_worker_node(req);
  mstate.wtag[0] = tag;
  mstate.cpuit = 0;
  mstate.cacheit = 0;
  mstate.randit = 0;
}
int find_free(){
    for(int i = 0; i < 4;i++){
        if(mstate.ws[i].is_alive == false){
            cout<< "ws "<<i <<" is not active"<<endl;
            return i;
        }
    }
    cout<<"all ws are occupied"<<endl;
    return -1;
}
int next_wh(int cur){
    while(true){
        cur = (cur+1)%4;
        if( (mstate.ws[cur].is_alive == true )&& ( mstate.ws[cur].claim_closed == false) )return cur;
    }
}
int mincpu_wh(){
    int mincpu = -1;
    int minv = 100000;
    for(int i = 0; i < 4;i++){
        if( (mstate.ws[i].is_alive == true )&& ( mstate.ws[i].claim_closed == false) ){
            int tmp = mstate.ws[i].cpu_reqnum ;
            if(tmp< minv){
                minv = tmp;
                mincpu =i;
            }
        }
    }
    return mincpu;
}
int mincache_wh(){
    int mincache = -1;
    int minv = 100000;
    for(int i = 0; i < 4;i++){
        if( (mstate.ws[i].is_alive == true )&& ( mstate.ws[i].claim_closed == false) ){
            int tmp = mstate.ws[i].cache_reqnum ;
            if(tmp< minv){
                minv = tmp;
                mincache =i;
            }
        }
    }
    return mincache;
}

int get_index_t(int tag){
    for(int i = 0; i < 4;i++){
        if(mstate.wtag[i] == tag)return i;
    }
    return -1;
}
int get_index_wh(Worker_handle worker_handle){
    for(int i = 0; i < 4;i++){
        if(mstate.my_worker[i] == worker_handle)return i;
    }
    return -1;
}
void reset_ws(int index){
    mstate.ws[index].is_alive = true;
    mstate.ws[index].claim_closed = false;
    mstate.ws[index].cpu_reqnum = 0;
    mstate.ws[index].mem_reqnum = 0;
    mstate.ws[index].cache_reqnum = 0;
    mstate.ws[index].idle_period = 0;
}
void handle_new_worker_online(Worker_handle worker_handle, int tag) {

  // 'tag' allows you to identify which worker request this response
  // corresponds to.  Since the starter code only sends off one new
  // worker request, we don't use it here.
  int index = get_index_t(tag);
  mstate.my_worker[index] = worker_handle;

  reset_ws(index);
  mstate.cur_num_workers++;
  cout<< "scale out! Handle worker online: [" <<worker_handle<<"  "<< index << ":" << tag << "] now num worker " << mstate.cur_num_workers<<std::endl;
  // Now that a worker is booted, let the system know the server is
  // ready to begin handling client requests.  The test harness will
  // now start its timers and start hitting your server with requests.
  if (mstate.server_ready == false) {
    server_init_complete();
     cout<< "init server"<<endl;
    mstate.server_ready = true;
  }
}

string get_key(Request_msg & req) {
    string cmd = req.get_arg("cmd");
    if(!cmd.compare("countprimes")) {
        return string("N#") + req.get_arg("n");
    }

    if(!cmd.compare("418wisdom")) {
        return string("4#") + req.get_arg("x");
    }

    if(!cmd.compare("compareprimes")) {
        return string("M#") + req.get_arg("n1") + ',' +
                              req.get_arg("n2") + ',' +
                              req.get_arg("n3") + ',' +
                              req.get_arg("n4");
    }

    if(!cmd.compare("tellmenow")) {
        return string("T#") + req.get_arg("x");
    }

    if(!cmd.compare("projectidea")) {
        return string("P#") + req.get_arg("x");
    }

    return "";
}
void send_request_to_lb2(const Request_msg& req){
    //wrap function, send req to lb and let lb figure out where to send the real requests.
    std::string cmd = req.get_arg("cmd");
    if (cmd.compare("418wisdom") == 0||cmd.compare("countprimes") == 0) {
        // compute intensive
        mstate.cpuit = next_wh(mstate.cpuit);
        cout<< "ELB send work: [" <<  mstate.my_worker[ mstate.cpuit ] << ":" << cmd << "]" << std::endl;
        send_request_to_worker(mstate.my_worker[ mstate.cpuit ], req);
        mstate.ws[mstate.cpuit].cpu_reqnum ++;
    }else if(cmd.compare("projectidea") == 0){
        //cache intensive
        mstate.cacheit = next_wh(mstate.cacheit);
        cout<< "ELB send work: [" << mstate.my_worker[ mstate.cacheit ] << ":" << cmd << "]" << std::endl;
        send_request_to_worker(mstate.my_worker[ mstate.cacheit ], req);
        mstate.ws[mstate.cacheit].cache_reqnum ++;
    }else{
        //do it randomly tellmenow
        mstate.randit = next_wh(mstate.randit);
        cout<< "ELB send work: [" <<  mstate.randit << ":" << cmd << "]" << std::endl;
        send_request_to_worker(mstate.my_worker[ mstate.randit ], req);

    }
}
void send_request_to_lb(const Request_msg& req){
    //wrap function, send req to lb and let lb figure out where to send the real requests.
    std::string cmd = req.get_arg("cmd");
    int goal;
    if (cmd.compare("418wisdom") == 0||cmd.compare("countprimes") == 0) {
        // compute intensive
        goal = mincpu_wh();
        cout<< "ELB send work: [" <<  mstate.my_worker[ goal] << ":" << cmd << "]" << std::endl;
        send_request_to_worker(mstate.my_worker[ goal], req);
        mstate.ws[goal].cpu_reqnum ++;
    }else if(cmd.compare("projectidea") == 0){
        //cache intensive
        goal = mincache_wh();
        cout<< "ELB send work: [" << mstate.my_worker[goal] << ":" << cmd << "]" << std::endl;
        send_request_to_worker(mstate.my_worker[ goal ], req);
        mstate.ws[goal].cache_reqnum ++;
    }else{
        //do it randomly tellmenow
        mstate.randit = next_wh(mstate.randit);
        cout<< "ELB send work: [" <<  mstate.randit << ":" << cmd << "]" << std::endl;
        send_request_to_worker(mstate.my_worker[ mstate.randit ], req);

    }
}
void handle_worker_response(Worker_handle worker_handle, const Response_msg& resp) {

  // Master node has received a response from one of its workers.
  // Here we directly return this response to the client.

  DLOG(INFO) << "Master received a response from a worker: [" << resp.get_tag() << ":" << resp.get_response() << "]" << std::endl;
  //cout << "Master received a response from a worker: [" << resp.get_tag() << ":" << resp.get_response() << "]" << std::endl;

  int tag = resp.get_tag();
  Client_handle client = mstate.clientMap[tag];
  Request_msg req = mstate.requestMap[tag];


  if(!req.get_arg("cmd").compare("compareprimes")) {
      string result = resp.get_response();
      int index = result[0]-'0';
      int count = atoi(result.substr(2).c_str());
      ++mstate.respNumMap[tag];
      mstate.countListMap[tag][index] = count;
      if(mstate.respNumMap[tag] == 4) {
          Response_msg new_resp;
          int c1 = mstate.countListMap[tag][1] - mstate.countListMap[tag][0];
          int c2 = mstate.countListMap[tag][3] - mstate.countListMap[tag][2];
          if (c1 > c2) {
              new_resp.set_response("There are more primes in first range.");
          } else {
              new_resp.set_response("There are more primes in second range.");
          }
          send_client_response(client, new_resp);
          mstate.countListMap.erase(tag);
          mstate.respNumMap.erase(tag);
          mstate.clientMap.erase(tag);
          mstate.requestMap.erase(tag);
      }

  } else {
      mstate.clientMap.erase(tag);
      mstate.requestMap.erase(tag);
      send_client_response(client, resp);
      // update cache
      string key = get_key(req);
      mstate.cache[key] = resp;
  }
  //TODO: check the claimed_closed here
  for(int i  = 0;i < 4;i++){
        if(mstate.ws[i].is_alive && mstate.ws[i].claim_closed){
            if(mstate.ws[i].cpu_reqnum+ mstate.ws[i].mem_reqnum+mstate.ws[i].cache_reqnum == 0)
                kill_worker_node(mstate.my_worker[i]);
                mstate.ws[i].is_alive = false;
                mstate.ws[i].claim_closed = false;
                mstate.cur_num_workers--;
                mstate.my_worker[i] = NULL;

                cout<<endl<< "warning! scale in completed! " << i << " and now  "<<mstate.cur_num_workers <<endl<<endl;

        }
  }
    std::string cmd = req.get_arg("cmd");
    if (cmd.compare("418wisdom") == 0||cmd.compare("countprimes") == 0) {
        // compute intensive
        int goal = get_index_wh(worker_handle);
        mstate.ws[goal].cpu_reqnum --;
    }else if(cmd.compare("projectidea") == 0){
        //cache intensive
        int goal = get_index_wh(worker_handle);
        mstate.ws[goal].cache_reqnum --;
    }else{
    }
  if(mstate.waitlist.size() == 0) {
      mstate.num_pending_client_requests--;
  } else {
      Request_msg new_worker_request = mstate.waitlist.front();
      mstate.waitlist.pop_front();
      //send_request_to_worker(worker_handle, new_worker_request);
      send_request_to_lb(new_worker_request);
  }
}



void handle_client_request(Client_handle client_handle, const Request_msg& client_req) {

  DLOG(INFO) << "Received request: " << client_req.get_request_string() << std::endl;

  // You can assume that traces end with this special message.  It
  // exists because it might be useful for debugging to dump
  // information about the entire run here: statistics, etc.
  if (client_req.get_arg("cmd") == "lastrequest") {
    Response_msg resp(0);
    resp.set_response("ack");
    send_client_response(client_handle, resp);
    return;
  }

  // The provided starter code cannot handle multiple pending client
  // requests.  The server returns an error message, and the checker
  // will mark the response as "incorrect"
  int tag = mstate.next_tag++;
  Request_msg worker_req(tag, client_req);
  mstate.clientMap[tag] = client_handle;
  mstate.requestMap[tag] = worker_req;

  string key = get_key(worker_req);
  //cout << tag << " has " << key << endl;

  if (mstate.cache.find(key) != mstate.cache.end()) {

      //cout << tag << " hit!" << endl;

      Response_msg resp = mstate.cache.find(key)->second;
      send_client_response(client_handle, resp);
      return;
  }


  string cmd = client_req.get_arg("cmd");
  if (!cmd.compare("compareprimes")) {
      int n[4];
      n[0] = atoi(worker_req.get_arg("n1").c_str());
      n[1] = atoi(worker_req.get_arg("n2").c_str());
      n[2] = atoi(worker_req.get_arg("n3").c_str());
      n[3] = atoi(worker_req.get_arg("n4").c_str());
      // initialize the sub-requests that have been completed
      //mstate.requestsMap[tag]->counts[4] = 0;
      for(int i = 0; i < 4; i++) {
          Request_msg new_req(tag);
          new_req.set_arg("cmd", "compareprimes");
          new_req.set_arg("n", to_string(n[i]));
          new_req.set_arg("index", to_string(i));
          mstate.waitlist.push_back(new_req);
      }
      mstate.respNumMap[tag] = 0;
      mstate.countListMap[tag] = vector<int>(4);

  } else if (!cmd.compare("tellmenow")) {
    //cout << "get tellmenow" << endl;
    //send_request_to_worker(mstate.my_worker, worker_req);
    send_request_to_lb(worker_req);
    return;
  } else {
    mstate.waitlist.push_back(worker_req);
  }


  //if (mstate.num_pending_client_requests <= pthread_num * mstate.cur_num_workers) {
  while(mstate.waitlist.size()>0){
    Request_msg new_worker_request = mstate.waitlist.front();
    mstate.waitlist.pop_front();
    //send_request_to_worker(mstate.my_worker, new_worker_request);
    send_request_to_lb(new_worker_request);
    mstate.num_pending_client_requests++;
    //return;
    //}else{
     //   break;
    //}
  }

  return;

  // Fire off the request to the worker.  Eventually the worker will
  // respond, and your 'handle_worker_response' event handler will be
  // called to forward the worker's response back to the server.


  // We're done!  This event handler now returns, and the master
  // process calls another one of your handlers when action is
  // required.

}


void handle_tick() {

  // TODO: you may wish to take action here.  This method is called at
  // fixed time intervals, according to how you set 'tick_period' in
  // 'master_node_init'.
  //TODO scale out and scale in
 int total_cpu =0;
 int total_cache =0;

 for(int i = 0; i < 4;i++){
     cout<<mstate.my_worker[i]<< i<<" :  alive "<<mstate.ws[i].is_alive<<" closed "<<mstate.ws[i].claim_closed<<" cpu "<<mstate.ws[i].cpu_reqnum<<" cache " << mstate.ws[i].cache_reqnum <<endl;
    if(mstate.ws[i].is_alive){
        total_cpu += mstate.ws[i].cpu_reqnum;
        total_cache +=mstate.ws[i].cache_reqnum;

        /*
        if(mstate.ws[i].claim_closed == false){//it is working!
              if(mstate.ws[i].cpu_reqnum+ mstate.ws[i].mem_reqnum+mstate.ws[i].cache_reqnum == 0){
                mstate.ws[i].idle_period +=1;
                if( mstate.ws[i].idle_period>=3){//scale in
                    mstate.ws[i].claim_closed = true;
                    mstate.ws[i].idle_period = 0;
                    break;//close only one at a time
                }
              }
        }
        */
    }
 }
 float avg_cpu = (float)total_cpu/mstate.cur_num_workers;
 float avg_cache = (float)total_cache/mstate.cur_num_workers;
 if(avg_cpu >pthread_num * 1.4|| avg_cache >1.4){//scale out
 //if(mstate.waitlist.size()>pthread_num /2){
     cout<<endl<< "warning! scale out needed! " << avg_cache << "  "<<avg_cpu <<"  "<< mstate.cur_num_workers<<" "<<mstate.max_num_workers<<endl<<endl;
     for(int i  = 0;i < 4;i++){
        if(mstate.ws[i].is_alive && mstate.ws[i].claim_closed){//we don't want to close want we claimed to be closed any more
            mstate.ws[i].claim_closed = false;
        }
    }
    if(mstate.cur_num_workers< mstate.max_num_workers){// add one machine
          int tag = random();
          int index = find_free();
          cout<<"found a free slot" <<index <<"for "<< tag <<endl;
          Request_msg req(tag);
          req.set_arg("name", "my worker "+to_string(index) );
          request_new_worker_node(req);
          mstate.wtag[index] = tag;

    }
    mstate.idle_cycle = 0;
 }else{
    mstate.idle_cycle +=1;
    if(mstate.idle_cycle >=2 && mstate.cur_num_workers >1){
        mstate.idle_cycle = 0;
         for(int i = 0; i < 4;i++){
            if(mstate.ws[i].is_alive && !mstate.ws[i].claim_closed){
                mstate.ws[i].claim_closed = true;
                cout<<endl<< "warning! scale in needed! " << avg_cache << "  "<<avg_cpu <<endl<<endl;
                break;
            }
        }
    }
 }
   //can also kill here, the check is the same as it is in handle_worker_response()
    for(int i  = 0;i < 4;i++){
        if(mstate.ws[i].is_alive && mstate.ws[i].claim_closed){
            if(mstate.ws[i].cpu_reqnum == 0 && mstate.ws[i].cache_reqnum == 0)
                kill_worker_node(mstate.my_worker[i]);
                mstate.ws[i].is_alive = false;
                mstate.ws[i].claim_closed = false;
                mstate.cur_num_workers--;
                cout<<endl<< "warning! scale in completed at 2! "<<mstate.my_worker[i]<<" killed " << i << " and now  "<<mstate.cur_num_workers <<endl<<endl;
                mstate.my_worker[i] = NULL;

        }
    }
}

